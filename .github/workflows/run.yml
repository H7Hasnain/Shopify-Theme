name: Run Puppeteer Scraper

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL to scrape'
        required: true
        default: 'https://example.com'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: |
          npm install puppeteer fs path https http readline

      - name: Prepare filename and run scraper
        env:
          TARGET_URL: ${{ github.event.inputs.url }}
        run: |
          echo "üåê Input URL: $TARGET_URL"

          # Extract main name from URL (remove http, https, www, .com, etc.)
          MAIN_NAME=$(echo "$TARGET_URL" | sed -E 's~https?://~~; s~www\.~~; s~\.com.*~~; s~/.*~~; s/[^a-zA-Z0-9_-]//g')
          OUTPUT_FILE="${MAIN_NAME}_scraped.html"

          echo "üìù Extracted name: $MAIN_NAME"
          echo "üìÑ Output file: $OUTPUT_FILE"

          # Run the scraper and simulate inputs for readline
          echo -e "$TARGET_URL\n$OUTPUT_FILE\n" | node scraper.js

      - name: Upload scraped HTML
        uses: actions/upload-artifact@v4
        with:
          name: scraped-html
          path: ./*_scraped.html
