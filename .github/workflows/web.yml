name: Scrape Website

on:
  repository_dispatch:
    types: [scrape-website]
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL'
        required: true
        type: string

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Puppeteer
        run: npm install puppeteer
        
      - name: Get URL
        id: get-url
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            URL="${{ github.event.client_payload.url }}"
          else
            URL="${{ inputs.url }}"
          fi
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "Scraping: $URL"
          
      - name: Run Scraper
        run: |
          echo "Starting scraper..."
          node scraper.js "${{ steps.get-url.outputs.url }}" > output.html 2>&1
          
          echo "Verifying output..."
          if [ ! -f output.html ]; then
            echo "ERROR: output.html not created"
            exit 1
          fi
          
          SIZE=$(wc -c < output.html)
          echo "Output size: $SIZE bytes"
          
          if [ $SIZE -lt 50 ]; then
            echo "ERROR: Output too small"
            cat output.html
            exit 1
          fi
          
      - name: Sanitize Output
        run: |
          echo "Removing sensitive data..."
          # Remove GitHub tokens (ghp_, gho_, ghs_, ghr_)
          sed -i 's/ghp_[a-zA-Z0-9]\{36\}/GITHUB_TOKEN_REMOVED/g' output.html
          sed -i 's/gho_[a-zA-Z0-9]\{36\}/GITHUB_TOKEN_REMOVED/g' output.html
          sed -i 's/ghs_[a-zA-Z0-9]\{36\}/GITHUB_TOKEN_REMOVED/g' output.html
          sed -i 's/ghr_[a-zA-Z0-9]\{36\}/GITHUB_TOKEN_REMOVED/g' output.html
          
          # Remove API keys patterns
          sed -i 's/Bearer [a-zA-Z0-9_-]\{20,\}/Bearer TOKEN_REMOVED/g' output.html
          
          echo "Sanitization complete"
          
      - name: Commit and Push
        run: |
          git config user.email "bot@github.com"
          git config user.name "GitHub Actions Bot"
          
          mkdir -p scraped-results
          
          TIMESTAMP=$(date +%s%N)
          FILENAME="scraped_${TIMESTAMP}.html"
          
          cp output.html "scraped-results/${FILENAME}"
          
          echo "Committing: ${FILENAME}"
          git add "scraped-results/${FILENAME}"
          git commit -m "Add scraped content: ${FILENAME}"
          git push origin main
          
          SIZE=$(wc -c < "scraped-results/${FILENAME}")
          echo "âœ… Success! File: ${FILENAME}, Size: $SIZE bytes"
