name: Scrape Website

on:
  repository_dispatch:
    types: [scrape-website]
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL'
        required: true
        type: string

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
        
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Puppeteer
        run: npm install puppeteer
        
      - name: Get URL
        id: get-url
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            URL="${{ github.event.client_payload.url }}"
          else
            URL="${{ inputs.url }}"
          fi
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "Scraping: $URL"
          
      - name: Run Scraper
        run: |
          node scraper.js "${{ steps.get-url.outputs.url }}" > output.html 2>&1
          echo "Scraping completed"
          ls -lh output.html
          
      - name: Commit and Push
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          mkdir -p scraped-results
          
          TIMESTAMP=$(date +%s%N)
          FILENAME="scraped_${TIMESTAMP}.html"
          
          cp output.html "scraped-results/${FILENAME}"
          
          git add scraped-results/${FILENAME}
          git commit -m "Add scraped content: ${FILENAME}"
          
          echo "Pushing to repository..."
          git push origin main
          
          echo "File committed: ${FILENAME}"
          echo "File size: $(wc -c < scraped-results/${FILENAME}) bytes"
