const puppeteer = require('puppeteer');

(async () => {
    try {
        const url = process.argv[2];
        
        if (!url) {
            console.error('No URL provided');
            process.exit(1);
        }

        console.error(`Starting Puppeteer for: ${url}`);

        const browser = await puppeteer.launch({
            headless: 'new',
            args: [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-gpu'
            ]
        });

        const page = await browser.newPage();
        
        await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36');
        
        console.error('Navigating to URL...');
        await page.goto(url, {
            waitUntil: 'networkidle2',
            timeout: 60000
        });

        console.error('Getting HTML content...');
        const html = await page.content();

        await browser.close();

        console.error(`Success! HTML length: ${html.length}`);
        console.log(html); // Output to stdout

    } catch (error) {
        console.error('Scraper error:', error.message);
        console.log('<html><body><h1>Scraping Failed</h1><p>Error: ' + error.message + '</p></body></html>');
        process.exit(0); // Exit with 0 so workflow doesn't fail
    }
})();
