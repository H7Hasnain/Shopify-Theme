name: Scrape Website

on:
  repository_dispatch:
    types: [scrape-website]
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL to scrape'
        required: true
        type: string

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install dependencies
        run: npm install puppeteer
        
      - name: Get URL
        id: get-url
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            URL="${{ github.event.client_payload.url }}"
          else
            URL="${{ inputs.url }}"
          fi
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "Scraping URL: $URL"
          
      - name: Run scraper
        run: |
          node scraper.js "${{ steps.get-url.outputs.url }}" > output.html 2> scraper.log
          echo "Scraping completed"
          cat scraper.log || true
          
      - name: Verify output
        run: |
          if [ ! -f output.html ]; then
            echo "Error: output.html not created"
            exit 1
          fi
          
          SIZE=$(wc -c < output.html)
          echo "Output size: ${SIZE} bytes"
          
          if [ ${SIZE} -lt 100 ]; then
            echo "Warning: Output file seems too small"
            cat output.html
          fi
          
      - name: Save to repository
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          mkdir -p scraped-results
          TIMESTAMP=$(date +%s)
          cp output.html "scraped-results/scraped_${TIMESTAMP}.html"
          
          git add scraped-results/
          git commit -m "Add scraped content (timestamp: ${TIMESTAMP})"
          git push
          
          echo "File saved: scraped-results/scraped_${TIMESTAMP}.html"
          
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraped-html
          path: output.html
          retention-days: 1
          
      - name: Clean old files
        run: |
          cd scraped-results
          FILE_COUNT=$(ls -1 scraped_*.html 2>/dev/null | wc -l)
          
          if [ ${FILE_COUNT} -gt 10 ]; then
            ls -t scraped_*.html | tail -n +11 | xargs rm -f
            cd ..
            git add scraped-results/
            git commit -m "Clean old files" || true
            git push || true
          fi
